{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_user_params = {\n",
    "    'model_depth': 3,        # 3, 5, 7\n",
    "    'prune layers': 'dense', # none, all, dense, or conv (does not work right now)\n",
    "    'verbose_level': 0\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pruning_user_params['model_depth']\n",
    "verbosity = pruning_user_params['verbose_level']\n",
    "\n",
    "mfccs_json_path = \"../mfccs_cnn_humpbackwhale_walrus_bowheadwhale_fin_finbackwhale_killerwhale_emptyocean.json\"\n",
    "saved_model_path = f'../saved_model/layers{depth}/'\n",
    "pruned_model_path = f'../saved_model/pruned_models/layers{depth}/'\n",
    "parameter_csv_path = f'../model-stats/layers-{depth}_filters-1-16_n-trail1.csv'\n",
    "plot_file_name = f'../images/layers-{depth}_baseline-and-pruned-model-size-vs.png'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the MFCC File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import load_cnn_json\n",
    "\n",
    "X, y, L = load_cnn_json(mfccs_json_path)\n",
    "print(f\"mapping the marine mammals: {L}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test sets\n",
    "from compression_lib import prepare_datasets\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X, y, 0.6, 0.5) # test size, vailidation size\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(saved_model_path)):\n",
    "    for f in filenames:\n",
    "        loaded_model = tf.keras.models.load_model(dirpath+f)\n",
    "        model_list.append(loaded_model)\n",
    "print(f'loaded in {len(model_list)} baseline models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Baseline Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = []\n",
    "for model in model_list:\n",
    "    test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    model_accuracy.append(test_accuracy)\n",
    "print(f'determined {len(model_accuracy)} accuracy values with max. accuracy: {max(model_accuracy)} and min accuracy: {min(model_accuracy)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Pruned Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prune_low_magnitude object\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_list = []\n",
    "for model in model_list:\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    pruned_model_list.append(model_for_pruning)\n",
    "print(f'created {len(pruned_model_list)} pruned models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "model_history = []\n",
    "for model in pruned_model_list:\n",
    "  history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                      validation_split=validation_split, callbacks=callbacks, verbose=verbosity)\n",
    "  model_history.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in model_history:\n",
    "    print (history.history['val_accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy values for Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_accuracy = []\n",
    "for model in pruned_model_list:\n",
    "   _, model_for_pruning_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "   pruned_model_accuracy.append(model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pruned_model_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dense_model_name, pruned_model in zip(filenames, pruned_model_list):\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "    pruned_keras_file = pruned_model_path + dense_model_name\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "    print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of Baseline Model Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import get_gzipped_model_size\n",
    "\n",
    "baseline_model_sizes = []\n",
    "for f in filenames:\n",
    "    baseline_model_path = saved_model_path + f\n",
    "    model_size = get_gzipped_model_size(baseline_model_path)\n",
    "    baseline_model_sizes.append(model_size)\n",
    "print(baseline_model_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Pruned Model Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import get_gzipped_model_size\n",
    "\n",
    "pruned_model_sizes = []\n",
    "for f in filenames:\n",
    "    model_path = pruned_model_path + f\n",
    "    model_size = get_gzipped_model_size(model_path)\n",
    "    pruned_model_sizes.append(model_size)\n",
    "print(pruned_model_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Baseline and Pruned Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(baseline_model_sizes, model_accuracy, 'o', color='blue')\n",
    "plt.plot(pruned_model_sizes, pruned_model_accuracy, 'o', color='red')\n",
    "plt.xlabel(\"Number of Bytes\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "aa = pd.read_csv(parameter_csv_path)  \n",
    "aa[\"Baseline Size\"] = baseline_model_sizes[:16]\n",
    "aa[\"Pruned Accuracy\"] = pruned_model_accuracy[:16]\n",
    "aa[\"Pruned Size\"] = pruned_model_sizes[:16]\n",
    "aa.to_csv(parameter_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mammal-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97c558dc638cdc67fa37b8cfa9525ef9b501ca9e8390da302e007edd8839b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
