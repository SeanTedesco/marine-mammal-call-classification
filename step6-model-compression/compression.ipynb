{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should change the format of this page to the following:\n",
    "\n",
    "1. Gather User Input\n",
    "2. Generate all required directories\n",
    "3. Load in training data\n",
    "4. Load in baseline models\n",
    "5. Generate List of Pruned Models\n",
    "6. Generate List of Quantized Models\n",
    "7. Determine Accuracies of Baseline, Pruned, Quantized Models\n",
    "8. Determine Size of Baseline, Pruned, Quantized Models\n",
    "9. Save Accuracies and Sizes to a CSV\n",
    "10. Plot Accuracy vs Size to a Figure and save it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_user_params = {\n",
    "    'model_depth': 7,        # 3, 5, 7\n",
    "    'trial_number': 3,\n",
    "    'prune layers': 'dense', # none, all, dense, or conv (does not work right now)\n",
    "    'verbose_level': 0\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pruning_user_params['model_depth']\n",
    "verbosity = pruning_user_params['verbose_level']\n",
    "trial_n = pruning_user_params['trial_number']\n",
    "\n",
    "mfccs_json_path         = \"../mfccs_cnn_humpbackwhale_walrus_bowheadwhale_fin_finbackwhale_killerwhale_emptyocean.json\"\n",
    "saved_model_path        = f'../saved_model/layers{depth}/trial{trial_n}/'\n",
    "pruned_model_path       = f'../saved_model/pruned_models/layers{depth}/trial{trial_n}/'\n",
    "quantized_model_path    = f'../saved_model/quantized_models/layers{depth}/trial{trial_n}/'\n",
    "parameter_csv_path      = f'../model-stats/layers-{depth}_filters-1-16_n-trail{trial_n}.csv'\n",
    "plot_file_name          = f'../images/layers-{depth}_trial{trial_n}_baseline-pruned-and-quantized-model-size-vs-accuracy.png'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the MFCC File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import load_cnn_json\n",
    "\n",
    "X, y, L = load_cnn_json(mfccs_json_path)\n",
    "print(f\"mapping the marine mammals: {L}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation and test sets\n",
    "from compression_lib import prepare_datasets\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X, y, 0.6, 0.5) # test size, vailidation size\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(saved_model_path)):\n",
    "    for f in filenames:\n",
    "        loaded_model = tf.keras.models.load_model(dirpath+f)\n",
    "        model_list.append(loaded_model)\n",
    "print(f'loaded in {len(model_list)} baseline models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Baseline Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = []\n",
    "for model in model_list:\n",
    "    test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    model_accuracy.append(test_accuracy)\n",
    "print(f'determined {len(model_accuracy)} accuracy values with max. accuracy: {max(model_accuracy)} and min accuracy: {min(model_accuracy)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Pruned Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prune_low_magnitude object\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate List of Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_list = []\n",
    "for model in model_list:\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    pruned_model_list.append(model_for_pruning)\n",
    "print(f'created {len(pruned_model_list)} pruned models')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "model_history = []\n",
    "for model in pruned_model_list:\n",
    "  history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                      validation_split=validation_split, callbacks=callbacks, verbose=verbosity)\n",
    "  model_history.append(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy values for Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_accuracy = []\n",
    "for model in pruned_model_list:\n",
    "   _, model_for_pruning_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "   pruned_model_accuracy.append(model_for_pruning_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dense_model_name, pruned_model in zip(filenames, pruned_model_list):\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "    pruned_keras_file = pruned_model_path + dense_model_name\n",
    "    tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "    print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of Baseline Model Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import get_gzipped_model_size\n",
    "\n",
    "baseline_model_sizes = []\n",
    "for f in filenames:\n",
    "    baseline_model_path = saved_model_path + f\n",
    "    model_size = get_gzipped_model_size(baseline_model_path)\n",
    "    baseline_model_sizes.append(model_size)\n",
    "print(baseline_model_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Pruned Model Memory Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import get_gzipped_model_size\n",
    "\n",
    "pruned_model_sizes = []\n",
    "for f in filenames:\n",
    "    model_path = pruned_model_path + f\n",
    "    model_size = get_gzipped_model_size(model_path)\n",
    "    pruned_model_sizes.append(model_size)\n",
    "print(pruned_model_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Baseline and Pruned Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(baseline_model_sizes, model_accuracy, 'o', color='blue')\n",
    "plt.plot(pruned_model_sizes, pruned_model_accuracy, 'o', color='red')\n",
    "plt.xlabel(\"Number of Bytes\")\n",
    "plt.ylabel(\"Model Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "aa = pd.read_csv(parameter_csv_path)  \n",
    "aa[\"Baseline Size\"] = baseline_model_sizes[:16]\n",
    "aa[\"Pruned Accuracy\"] = pruned_model_accuracy[:16]\n",
    "aa[\"Pruned Size\"] = pruned_model_sizes[:16]\n",
    "aa.to_csv(parameter_csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(X_test):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == y_test).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# must make the folders:\n",
    "|- quantized_models\n",
    "|  |- layers3\n",
    "|  |   |- trial1\n",
    "|  |   |- trial2\n",
    "|  |   |- trial3\n",
    "|  |- layers5\n",
    "|  |   |- trial1\n",
    "|  |   |- trial2\n",
    "|  |   |- trial3\n",
    "|  |- layers7\n",
    "|  |   |- trial1\n",
    "|  |   |- trial2\n",
    "|  |   |- trial3\n",
    "\"\"\"\n",
    "\n",
    "quantized_model_list = []\n",
    "for dense_model_name, pruned_model in zip(filenames, pruned_model_list):\n",
    "  model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "  quantized_keras_path = quantized_model_path + dense_model_name[:len(dense_model_name)-3] + \".tflite\"\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "  quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "  with open(quantized_keras_path, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "  print('Saved quantized and pruned TFLite model to:', quantized_keras_path)\n",
    "  quantized_model_list.append(quantized_and_pruned_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "quantized_model_accuracy = []\n",
    "for quantized_model in quantized_model_list:\n",
    "    interpreter = tf.lite.Interpreter(model_content=quantized_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    test_accuracy = evaluate_model(interpreter)\n",
    "    quantized_model_accuracy.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quantized_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_lib import get_gzipped_model_size\n",
    "\n",
    "quantized_model_sizes = []\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(quantized_model_path)):\n",
    "    for f in filenames:\n",
    "        model_path = quantized_model_path + f\n",
    "        model_size = get_gzipped_model_size(model_path)\n",
    "        quantized_model_sizes.append(model_size)\n",
    "print(quantized_model_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(baseline_model_sizes, model_accuracy, 'o', color='blue')\n",
    "plt.plot(pruned_model_sizes, pruned_model_accuracy, 'o', color='red')\n",
    "plt.plot(quantized_model_sizes, quantized_model_accuracy, 'o', color='green')\n",
    "plt.xlabel(\"Number of Bytes\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.legend([\"Baseline Models\", \"Pruned Models\", \"Pruned and Quantized Models\"])\n",
    "plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "aa = pd.read_csv(parameter_csv_path)  \n",
    "aa[\"Quantized Accuracy\"] = quantized_model_accuracy[:16]\n",
    "aa[\"Quantized Size\"] = quantized_model_sizes[:16]\n",
    "aa.to_csv(parameter_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_30_input:0', 'index': 0, 'shape': array([  1, 130,  13,   1], dtype=int32), 'shape_signature': array([ -1, 130,  13,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "(130, 13, 1)\n",
      "the output is [[1.6453000e-06 1.8397979e-05 1.2731196e-04 1.1345492e-03 9.9871814e-01\n",
      "  2.7908094e-08 9.6622665e-10]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from compression_lib import load_cnn_json\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../saved_model/gui_models/arduino_mega.tflite\")\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "# need to reshape the data \n",
    "signal, y, l = load_cnn_json(\"../mfccs_gui_test.json\")\n",
    "signal = np.float32(signal)[0]\n",
    "signal = signal[:,:, np.newaxis]\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], [signal])\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(\"the output is {}\".format(output_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mammal-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97c558dc638cdc67fa37b8cfa9525ef9b501ca9e8390da302e007edd8839b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
